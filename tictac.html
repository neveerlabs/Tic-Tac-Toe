<!doctype html>
<html lang="id">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Tic-Tac-Toe ‚Äî Q-Learning RL</title>
<style>
  :root{
    --bg-1: #0a0a0a;
    --bg-2: #121212;
    --accent-1: #1a2a6c;
    --accent-2: #2a1a6c;
    --blue: #4da6ff;
    --red: #ff4d4d;
    --glass: rgba(255,255,255,0.03);
    --muted: rgba(255,255,255,0.12);
    --gold: #FFD700;
    --font-sans: system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
  }
  *{box-sizing:border-box}
  html,body{height:100%;margin:0;background:
    radial-gradient(1200px 600px at 10% 10%, rgba(29,41,72,0.15), transparent),
    radial-gradient(900px 400px at 90% 90%, rgba(42,26,108,0.12), transparent),
    var(--bg-1); color:#eaeef6; font-family:var(--font-sans);}
  .wrap{min-height:100vh;display:flex;align-items:center;justify-content:center;padding:24px;}
  .container{
    width:min(1000px,96vw); max-width:1000px; background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));
    border-radius:18px; padding:20px; display:grid; grid-template-columns:1fr 360px; gap:20px; align-items:start;
    backdrop-filter: blur(8px); box-shadow: 0 6px 30px rgba(2,6,23,0.6); border:1px solid rgba(255,255,255,0.03);
  }
  .board-wrap{display:flex;flex-direction:column;gap:16px;}
  header.top{display:flex;justify-content:space-between;align-items:center;gap:12px;}
  .score-panel{display:flex;gap:12px;align-items:center;}
  .score{display:flex;gap:10px;align-items:center;padding:8px 12px;border-radius:12px;background:linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.00));border:1px solid rgba(255,255,255,0.03);min-width:120px;justify-content:space-between;}
  .score .label{opacity:0.8;font-size:13px} .score .value{font-weight:700;font-size:18px}
  .controls{display:flex;gap:8px;align-items:center;}
  .btn{background:transparent;border:1px solid rgba(255,255,255,0.04);padding:8px 10px;border-radius:10px;cursor:pointer;font-size:14px;transition:transform .14s ease, background .14s ease, border-color .14s;display:inline-flex;align-items:center;gap:8px;}
  .btn:hover{ transform:translateY(-3px); border-color: rgba(77,166,255,0.18); background: rgba(255,255,255,0.01)}
  .btn.small{padding:6px 8px;font-size:13px}
  .board{width:100%;aspect-ratio:1;display:grid;grid-template-columns:repeat(3,1fr);grid-template-rows:repeat(3,1fr);gap:12px;padding:12px;border-radius:16px;background:linear-gradient(180deg, rgba(255,255,255,0.015), rgba(255,255,255,0.01));box-shadow: inset 0 -2px 24px rgba(0,0,0,0.5);border:1px solid rgba(255,255,255,0.03);}
  .cell{background: linear-gradient(180deg, rgba(255,255,255,0.005), rgba(0,0,0,0.2));border-radius:12px;display:flex;align-items:center;justify-content:center;font-size:48px;user-select:none;cursor:pointer;position:relative;transition: transform .12s ease, background .12s ease, box-shadow .12s ease;box-shadow: 0 6px 18px rgba(0,0,0,0.6);border:1px solid rgba(255,255,255,0.02);}
  .cell:hover{ transform: scale(1.03) translateY(-2px); box-shadow: 0 10px 26px rgba(0,0,0,0.7) }
  .cell.disabled{ cursor:not-allowed; opacity:0.9; transform:none }
  .cell.x{ color: var(--red); font-weight:800; text-shadow: 0 2px 12px rgba(255,77,77,0.08) }
  .cell.o{ color: var(--blue); font-weight:800; text-shadow: 0 2px 12px rgba(77,166,255,0.08) }
  .marker{display:inline-block;transform: scale(0.2) rotate(-6deg);opacity:0;animation: pop-in .18s cubic-bezier(.2,.85,.3,1) forwards;}
  @keyframes pop-in{ to { transform: scale(1) rotate(0deg); opacity:1; } }
  .cell.win { box-shadow: 0 0 28px 6px rgba(77,166,255,0.08), 0 8px 32px rgba(0,0,0,0.6); transform: scale(1.05); animation: glow 1.2s infinite alternate; }
  @keyframes glow{ to { box-shadow: 0 0 48px 10px rgba(77,166,255,0.12), 0 10px 40px rgba(0,0,0,0.6); } }
  .side{display:flex;flex-direction:column;gap:12px;align-items:stretch;}
  .panel{padding:14px;border-radius:12px;background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.005));border:1px solid rgba(255,255,255,0.03);}
  .panel h3{ margin:0 0 8px 0; font-size:16px } .panel p{ margin:0; font-size:13px; color:rgba(255,255,255,0.78) }
  .stat-list{ display:flex; gap:8px; align-items:center; justify-content:space-between; margin-top:8px }
  .stat{ font-weight:700; font-size:15px } .small-muted{ font-size:12px; color:rgba(255,255,255,0.5) }
  .overlay{ position:fixed; inset:0; display:none; align-items:center; justify-content:center; z-index:60; backdrop-filter: blur(6px); background: linear-gradient(180deg, rgba(2,6,23,0.6), rgba(2,6,23,0.72)); }
  .overlay.active{ display:flex } .result-card{ width:min(720px,92vw); padding:28px; border-radius:16px; text-align:center; background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)); border:1px solid rgba(255,255,255,0.04); box-shadow: 0 12px 48px rgba(2,6,23,0.78); }
  .result-card h1{ margin:0; font-size:44px } .crown{ font-size:48px; display:inline-block; margin-right:10px; animation: crown-bounce .9s ease infinite alternate; } @keyframes crown-bounce { to { transform: translateY(-8px) rotate(-6deg); } }
  .result-card p{ margin:8px 0 16px 0; font-size:16px } .result-actions{ display:flex; gap:10px; justify-content:center; margin-top:14px } .glow{ box-shadow: 0 8px 44px rgba(77,166,255,0.14), inset 0 -4px 12px rgba(0,0,0,0.25); }
  @media (max-width:880px){ .container{ grid-template-columns: 1fr; } .side{ order:2 } }
  #particle-canvas{ position:fixed; inset:0; pointer-events:none; z-index:55; }
  .tiny{ font-size:12px; opacity:0.9; }
  .progress{ height:10px; background:rgba(255,255,255,0.03); border-radius:6px; overflow:hidden; margin-top:8px; }
  .progress > i{ display:block; height:100%; background:linear-gradient(90deg,var(--blue), #9be1ff); width:0%; transition:width .12s linear; }
</style>
</head>
<body>
<div class="wrap">
  <div class="container" role="application" aria-label="Tic Tac Toe RL Updated">
    <div class="board-wrap">
      <header class="top">
        <div class="score-panel">
          <div class="score" id="playerScoreBox" title="Player (You)">
            <div style="display:flex;gap:8px;align-items:center">
              <div style="font-size:18px">üë§</div>
              <div>
                <div class="label">Neverlabs</div>
                <div class="value" id="playerScore">0</div>
              </div>
            </div>
          </div>
          <div class="score" id="aiScoreBox" title="AI">
            <div style="display:flex;gap:8px;align-items:center">
              <div style="font-size:18px">ü§ñ</div>
              <div>
                <div class="label">AI</div>
                <div class="value" id="aiScore">0</div>
              </div>
            </div>
          </div>
        </div>

        <div class="controls">
          <button class="btn small" id="resetScoreBtn" title="Reset skor">üîÑ Reset Skor</button>
          <button class="btn small" id="homeBtn" title="Kembali ke beranda">üè† Home</button>
        </div>
      </header>

      <main>
        <div class="board" id="board" role="grid" aria-label="Board">
          <!-- cells by JS -->
        </div>
      </main>

      <footer style="display:flex;justify-content:space-between;align-items:center;margin-top:10px">
        <div style="display:flex;gap:8px;align-items:center">
          <div class="small-muted">Giliran: <strong id="turnLabel">Neverlabs (X)</strong></div>
        </div>
        <div style="display:flex;gap:8px;align-items:center">
          <div class="small-muted">Epsilon: <strong id="epsilonLabel">0.20</strong></div>
        </div>
      </footer>
    </div>

    <aside class="side">
      <div class="panel">
        <h3>AI Learning (Q-Learning) ‚Äî Improved</h3>
        <p class="tiny">AI sekarang cek kemenangan 1-langkah (take win / block), dan dapat dilatih otomatis via tombol Train.</p>
        <div class="stat-list">
          <div>
            <div class="small-muted">Q-States</div>
            <div class="stat" id="qStatesCount">0</div>
          </div>
          <div>
            <div class="small-muted">Version</div>
            <div class="stat">v2</div>
          </div>
        </div>
        <div style="margin-top:10px;display:flex;gap:8px">
          <button class="btn" id="trainBtn">üèãÔ∏è Train AI (1000)</button>
          <button class="btn" id="train5000Btn">üèãÔ∏è‚Äç‚ôÇÔ∏è Train (5000)</button>
        </div>
        <div class="progress" id="trainProgress" style="display:none"><i></i></div>
        <div style="margin-top:8px;display:flex;gap:8px">
          <button class="btn" id="exportBtn">‚¨áÔ∏è Export Q</button>
          <button class="btn" id="importBtn">‚¨ÜÔ∏è Import Q</button>
          <button class="btn" id="clearQBtn">üß† Reset Memory</button>
        </div>
      </div>

      <div class="panel">
        <h3>Parameters</h3>
        <p class="small-muted">Ubah parameter untuk eksperimen. Default disetel untuk balancing eksplorasi & belajar cepat.</p>
        <div style="display:flex;flex-direction:column;gap:8px;margin-top:8px">
          <label class="small-muted">Epsilon (explore): <strong id="epsVal">0.20</strong></label>
          <input id="epsilonRange" type="range" min="0" max="0.5" step="0.01" value="0.20" />
          <label class="small-muted">Learning Rate: <strong id="lrVal">0.10</strong></label>
          <input id="lrRange" type="range" min="0.01" max="0.5" step="0.01" value="0.10" />
          <label class="small-muted">Discount (gamma): <strong id="gammaVal">0.90</strong></label>
          <input id="gammaRange" type="range" min="0.5" max="0.99" step="0.01" value="0.90" />
          <label class="small-muted"><input type="checkbox" id="decayEps" /> Decay epsilon during training</label>
        </div>
      </div>

      <div class="panel">
        <h3>Info & Tips</h3>
        <p>Neverlabs = X (merah). AI = O (biru). Neverlabs selalu mulai terlebih dahulu.</p>
        <p class="tiny" style="margin-top:8px">Untuk membuat AI semakin kuat: jalankan "Train AI (5000)" lalu coba main. AI akan belajar dari banyak permainan</p>
      </div>
    </aside>

  </div>
</div>

<canvas id="particle-canvas"></canvas>

<div class="overlay" id="overlay" role="dialog" aria-modal="true">
  <div class="result-card" id="resultCard">
    <div style="display:flex;align-items:center;justify-content:center">
      <div class="crown" id="crownIcon" style="display:none">üëë</div>
      <h1 id="resultTitle">You Win!</h1>
    </div>
    <p id="resultMsg">Keterangan hasil pertandingan</p>
    <div class="result-actions">
      <button class="btn glow" id="playAgainBtn">üîÅ Play Again</button>
      <button class="btn" id="homeBtn2">üè† Home</button>
    </div>
  </div>
</div>

<script>
/* ==========================
   Tic-Tac-Toe Q-Learning (v2)
   Features added:
   - immediate tactical checks (take win / block)
   - training automation (self-play vs smart-random opponent)
   - epsilon decay option during training
   - better Q initialization & updates
   All in one file.
   ========================== */

/* ---------- Config & State ---------- */
const STORAGE_KEY_Q = 'ttt_qtable_v2';
const STORAGE_KEY_SCORE = 'ttt_scores_v2';

let EPSILON = 0.20;        // initial exploration
let LEARNING_RATE = 0.10;  // alpha
let DISCOUNT = 0.90;       // gamma

const PLAYER = 'X';
const AI = 'O';

let boardState = Array(9).fill('_');
let gameActive = true;
let playerTurn = true;
let playerScore = 0, aiScore = 0;
let qTable = {}; // stateStr -> { actionIndex: qValue }
let moveHistory = []; // records AI moves: {state, action, nextState}
let trainingRunning = false;

/* ---------- DOM ---------- */
const boardEl = document.getElementById('board');
const playerScoreEl = document.getElementById('playerScore');
const aiScoreEl = document.getElementById('aiScore');
const qStatesCountEl = document.getElementById('qStatesCount');
const overlay = document.getElementById('overlay');
const resultTitle = document.getElementById('resultTitle');
const resultMsg = document.getElementById('resultMsg');
const crownIcon = document.getElementById('crownIcon');
const trainBtn = document.getElementById('trainBtn');
const train5000Btn = document.getElementById('train5000Btn');
const trainProgress = document.getElementById('trainProgress');
const trainProgressBar = trainProgress.querySelector('i');
const resetScoreBtn = document.getElementById('resetScoreBtn');
const homeBtn = document.getElementById('homeBtn');
const playAgainBtn = document.getElementById('playAgainBtn');
const homeBtn2 = document.getElementById('homeBtn2');
const clearQBtn = document.getElementById('clearQBtn');
const exportBtn = document.getElementById('exportBtn');
const importBtn = document.getElementById('importBtn');

const epsilonRange = document.getElementById('epsilonRange');
const lrRange = document.getElementById('lrRange');
const gammaRange = document.getElementById('gammaRange');
const epsVal = document.getElementById('epsVal');
const lrVal = document.getElementById('lrVal');
const gammaVal = document.getElementById('gammaVal');
const epsilonLabel = document.getElementById('epsilonLabel');
const decayEpsCheckbox = document.getElementById('decayEps');

/* particle canvas */
const particleCanvas = document.getElementById('particle-canvas');
const pcCtx = particleCanvas.getContext('2d');
let particles=[];
resizeCanvas();
window.addEventListener('resize', resizeCanvas);

/* ---------- Init ---------- */
loadQTable();
loadScores();
renderBoard();
updateUI();
attachEvents();

/* ---------- UI / Board ---------- */
function renderBoard(){
  boardEl.innerHTML = '';
  boardState.forEach((v,i)=>{
    const cell = document.createElement('div');
    cell.className = 'cell' + (v==='X' ? ' x' : v==='O' ? ' o' : '');
    cell.dataset.index = i;
    cell.setAttribute('role','button');
    cell.setAttribute('aria-label','Cell ' + (i+1));
    if(v !== '_'){
      const sp = document.createElement('span'); sp.className='marker'; sp.textContent = v;
      cell.appendChild(sp); cell.classList.add('disabled');
    } else {
      cell.innerHTML = '';
      cell.classList.remove('disabled');
    }
    cell.addEventListener('click', onCellClick);
    boardEl.appendChild(cell);
  });
}

function highlightWinning(indices){
  indices.forEach(i=>{
    const el = boardEl.querySelector(`.cell[data-index="${i}"]`);
    if(el) el.classList.add('win');
  });
}
function clearWinningHighlights(){
  boardEl.querySelectorAll('.cell.win').forEach(el=>el.classList.remove('win'));
}
function updateUI(){
  playerScoreEl.textContent = playerScore;
  aiScoreEl.textContent = aiScore;
  qStatesCountEl.textContent = Object.keys(qTable).length;
  document.getElementById('epsVal').textContent = EPSILON.toFixed(2);
  document.getElementById('lrVal').textContent = LEARNING_RATE.toFixed(2);
  document.getElementById('gammaVal').textContent = DISCOUNT.toFixed(2);
  document.getElementById('epsilonLabel').textContent = EPSILON.toFixed(2);
  document.getElementById('turnLabel').textContent = playerTurn ? 'Player (X)' : 'AI (O)';
}

/* ---------- Events ---------- */
function attachEvents(){
  resetScoreBtn.addEventListener('click', ()=>{ playerScore=0; aiScore=0; saveScores(); updateUI(); });
  homeBtn.addEventListener('click', ()=>location.reload());
  homeBtn2.addEventListener('click', ()=>location.reload());
  playAgainBtn.addEventListener('click', ()=>{ hideResult(); newRound(); });

  clearQBtn.addEventListener('click', ()=>{ if(confirm('Reset AI memory?')){ qTable={}; saveQTable(); updateUI(); alert('AI memory cleared.'); } });

  exportBtn.addEventListener('click', ()=>{ const data = JSON.stringify(qTable); const blob = new Blob([data], {type:'application/json'}); const url = URL.createObjectURL(blob); const a=document.createElement('a'); a.href=url; a.download='qtable_ttt_v2.json'; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url); });

  importBtn.addEventListener('click', ()=>{
    const input=document.createElement('input'); input.type='file'; input.accept='application/json';
    input.onchange = e=>{
      const f = e.target.files[0]; if(!f) return;
      const reader = new FileReader();
      reader.onload = ev=>{
        try{
          const obj = JSON.parse(ev.target.result);
          if(typeof obj === 'object' && obj !== null){ qTable = obj; saveQTable(); updateUI(); alert('Imported Q-table.'); } else throw new Error('Invalid format');
        }catch(err){ alert('Import failed: ' + err.message); }
      }; reader.readAsText(f);
    };
    input.click();
  });

  epsilonRange.addEventListener('input', e=>{ EPSILON = parseFloat(e.target.value); updateUI(); });
  lrRange.addEventListener('input', e=>{ LEARNING_RATE = parseFloat(e.target.value); updateUI(); });
  gammaRange.addEventListener('input', e=>{ DISCOUNT = parseFloat(e.target.value); updateUI(); });

  trainBtn.addEventListener('click', ()=>{ if(!trainingRunning) runTraining(1000); else alert('Training sedang berjalan'); });
  train5000Btn.addEventListener('click', ()=>{ if(!trainingRunning) runTraining(5000); else alert('Training sedang berjalan'); });
}

/* ---------- Player actions ---------- */
function onCellClick(e){
  if(!gameActive || !playerTurn) return;
  const idx = parseInt(e.currentTarget.dataset.index,10);
  if(boardState[idx] !== '_') return;
  makeMove(idx, PLAYER);
}

/* ---------- Core: make move ---------- */
function makeMove(idx, symbol){
  if(!gameActive) return;
  if(boardState[idx] !== '_') return;
  boardState[idx] = symbol;
  renderBoard();
  const res = checkWinner(boardState);
  if(res.winner){
    gameActive=false;
    handleGameOver(res.winner, res.indices);
    return;
  } else if(res.draw){
    gameActive=false;
    handleGameOver('draw');
    return;
  }
  playerTurn = (symbol !== PLAYER);
  updateUI();
  if(!playerTurn){
    setTimeout(()=> makeAIMove(), 200);
  }
}

/* ---------- AI decision improvements ----------
   1) If AI can win in one move => take it
   2) Else if Player can win next move => block it
   3) Else choose by epsilon-greedy on qTable
   Additionally: ensure qTable[state] initialized and actions exist with 0.0
   -------------------------------------------------- */
function makeAIMove(){
  const state = stateStr(boardState);
  const avail = availableMoves(boardState);
  if(avail.length === 0) return;

  // tactical: take immediate win
  const winningIdx = findWinningMove(boardState, AI);
  if(winningIdx !== -1){
    recordAIMoveAndApply(state, winningIdx);
    return;
  }
  // tactical: block immediate player win
  const blockIdx = findWinningMove(boardState, PLAYER);
  if(blockIdx !== -1){
    recordAIMoveAndApply(state, blockIdx);
    return;
  }

  // ensure qTable entry exists
  if(!qTable[state]) qTable[state] = {};
  avail.forEach(a=> { if(qTable[state][a] === undefined) qTable[state][a] = 0.0; });

  let chosen;
  if(Math.random() < EPSILON){
    chosen = avail[Math.floor(Math.random()*avail.length)];
  } else {
    // choose best Q (random tie-break)
    let maxQ = -Infinity; let best = [];
    avail.forEach(a=>{
      const q = qTable[state][a] ?? 0.0;
      if(q > maxQ){ maxQ = q; best = [a]; }
      else if(q === maxQ){ best.push(a); }
    });
    if(best.length === 0) chosen = avail[Math.floor(Math.random()*avail.length)];
    else chosen = best[Math.floor(Math.random()*best.length)];
  }

  recordAIMoveAndApply(state, chosen);
}

function recordAIMoveAndApply(state, actionIdx){
  // apply move
  boardState[actionIdx] = AI;
  // record for learning
  const next = stateStr(boardState);
  moveHistory.push({state, action: actionIdx, nextState: next});
  renderBoard();

  const res = checkWinner(boardState);
  if(res.winner){
    gameActive=false;
    handleGameOver(res.winner, res.indices);
    return;
  } else if(res.draw){
    gameActive=false;
    handleGameOver('draw');
    return;
  }
  playerTurn = true;
  updateUI();
}

/* ---------- Helpers: tactical checks ---------- */
function findWinningMove(board, symbol){
  const avail = availableMoves(board);
  for(const idx of avail){
    const copy = board.slice(); copy[idx]=symbol;
    const r = checkWinner(copy);
    if(r.winner === symbol) return idx;
  }
  return -1;
}

function availableMoves(board){ const arr=[]; board.forEach((v,i)=>{ if(v==='_' ) arr.push(i); }); return arr; }
function stateStr(board){ return board.join(''); }

/* ---------- Q-Learning update (backwards) ---------- */
/*
 Update only AI's moves recorded in moveHistory.
 reward: +1 AI win, -1 AI loss, 0 draw.
 For each AI move from last to first:
   currentQ = qTable[state][action]
   maxNextQ = max(qTable[nextState][*]) or 0
   target = reward + DISCOUNT * maxNextQ
   newQ = currentQ + LEARNING_RATE * (target - currentQ)
 After first update set reward=0 for previous steps.
*/
function updateQValues(finalReward){
  let reward = finalReward;
  for(let i=moveHistory.length-1; i>=0; i--){
    const {state, action, nextState} = moveHistory[i];
    if(!qTable[state]) qTable[state] = {};
    if(qTable[state][action] === undefined) qTable[state][action] = 0.0;
    const currentQ = qTable[state][action];

    let maxNextQ = 0;
    if(qTable[nextState]){
      const vals = Object.values(qTable[nextState]);
      if(vals.length) maxNextQ = Math.max(...vals);
    }
    const target = reward + (DISCOUNT * maxNextQ);
    const newQ = currentQ + (LEARNING_RATE * (target - currentQ));
    qTable[state][action] = newQ;
    reward = 0;
  }
  moveHistory = [];
  saveQTable();
}

/* ---------- End of game handling ---------- */
function handleGameOver(result, winIndices=[]){
  clearWinningHighlights();
  if(result === PLAYER){
    playerScore++; saveScores();
    highlightWinning(winIndices);
    showResult('You Win!', 'Kamu menang. AI menerima -1 reward.', 'win');
    updateQValues(-1); // AI lost
  } else if(result === AI){
    aiScore++; saveScores();
    highlightWinning(winIndices);
    showResult('You Lose!', 'AI menang. AI menerima +1 reward.', 'lose');
    updateQValues(+1);
    startParticles();
  } else {
    showResult('Draw!', 'Hasil seri. Reward 0 untuk AI.', 'draw');
    updateQValues(0);
  }
  updateUI();
}

function showResult(title, msg, type){
  overlay.classList.add('active');
  resultTitle.textContent = title;
  resultMsg.textContent = msg;
  crownIcon.style.display = (type === 'win' ? 'inline-block' : 'none');
}
function hideResult(){
  overlay.classList.remove('active');
}

/* ---------- New round ---------- */
function newRound(){
  boardState = Array(9).fill('_');
  gameActive = true;
  playerTurn = true;
  moveHistory = [];
  clearWinningHighlights();
  renderBoard();
  updateUI();
}

/* ---------- Persistence ---------- */
function saveQTable(){
  try{ localStorage.setItem(STORAGE_KEY_Q, JSON.stringify(qTable)); }catch(err){ console.warn('Save Q failed', err); }
}
function loadQTable(){
  try{
    const raw = localStorage.getItem(STORAGE_KEY_Q);
    if(raw){ const obj = JSON.parse(raw); if(typeof obj === 'object' && obj !== null){ qTable = obj; return; } }
  }catch(err){ console.warn('Load Q failed', err); }
  qTable = {};
}
function saveScores(){ try{ localStorage.setItem(STORAGE_KEY_SCORE, JSON.stringify({player:playerScore, ai:aiScore})); }catch(e){} }
function loadScores(){
  try{
    const raw = localStorage.getItem(STORAGE_KEY_SCORE);
    if(raw){ const s = JSON.parse(raw); playerScore = s.player || 0; aiScore = s.ai || 0; return; }
  }catch(e){}
  playerScore = 0; aiScore = 0;
}

/* ---------- Training (simulate many games) ----------
   Simulation specifics:
   - Opponent (X) moves: if immediate win available, take it; else choose random available.
   - AI moves: same logic as real AI (tactical + epsilon-greedy)
   - record AI moves and update Q at end of simulated game
   - option to decay epsilon gradually during training
   - run in small chunks to keep UI responsive
---------------------------------------------- */
async function runTraining(totalGames){
  trainingRunning = true;
  trainProgress.style.display = 'block';
  trainProgressBar.style.width = '0%';
  const originalEps = EPSILON;
  const decay = decayEpsCheckbox.checked;
  for(let g=0; g<totalGames; g++){
    // optionally decay epsilon linearly
    if(decay){
      EPSILON = Math.max(0.01, originalEps * (1 - (g / totalGames)));
    }
    // simulate one game
    await simulateOneGame();
    // progress UI
    if((g+1) % Math.max(1, Math.floor(totalGames/100)) === 0){
      trainProgressBar.style.width = Math.round(((g+1)/totalGames)*100) + '%';
      qStatesCountEl.textContent = Object.keys(qTable).length;
      // yield control briefly
      await new Promise(r => setTimeout(r, 0));
    }
  }
  EPSILON = originalEps;
  trainingRunning = false;
  trainProgress.style.display = 'none';
  updateUI();
  alert('Training selesai: ' + totalGames + ' games.');
}

/* simulateOneGame: returns Promise so we can yield */
function simulateOneGame(){
  return new Promise(resolve=>{
    // local simulated board & moveHistorySim
    let simBoard = Array(9).fill('_');
    let simMoveHistory = []; // record AI moves sim {state, action, nextState}
    let simPlayerTurn = true; // player X starts
    let simActive = true;

    // helper local functions to use same Q-table & tactics
    function simAvailable(b){ const arr=[]; b.forEach((v,i)=>{ if(v==='_' ) arr.push(i); }); return arr; }
    function simCheckWinner(b){
      const lines = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]];
      for(const [a,b1,c] of lines) if(b[a] !== '_' && b[a] === b[b1] && b[b1] === b[c]) return {winner: b[a], indices:[a,b1,c]};
      if(b.every(x=>x!=='_')) return {winner:'draw', indices:[]};
      return {winner:null, indices:[]};
    }
    function simFindWinMove(b, sym){
      const av = simAvailable(b);
      for(const idx of av){
        const copy = b.slice(); copy[idx]=sym;
        const r = simCheckWinner(copy);
        if(r.winner === sym) return idx;
      }
      return -1;
    }

    // run small synchronous loop (no heavy work)
    while(simActive){
      if(simPlayerTurn){
        // player's simulated strategy: take immediate winning move if possible, else random
        const pWin = simFindWinMove(simBoard, PLAYER);
        let chosen;
        if(pWin !== -1) chosen = pWin;
        else {
          const av = simAvailable(simBoard);
          chosen = av[Math.floor(Math.random()*av.length)];
        }
        simBoard[chosen] = PLAYER;
        const res = simCheckWinner(simBoard);
        if(res.winner){
          simActive=false;
          // update q with reward -1 (AI lost)
          // but need to set moveHistory from simMoveHistory
          // apply updates:
          applySimUpdates(simMoveHistory, res.winner === PLAYER ? -1 : (res.winner === AI ? +1 : 0));
          break;
        }
        simPlayerTurn = false;
      } else {
        // AI move in simulation: same as real AI logic but using current global qTable
        const curState = simBoard.join('');
        const av = simAvailable(simBoard);
        if(av.length === 0){ simActive=false; applySimUpdates(simMoveHistory, 0); break; }
        // tactical:
        const winIdx = simFindWinMove(simBoard, AI);
        if(winIdx !== -1){
          simBoard[winIdx] = AI;
          simMoveHistory.push({state: curState, action: winIdx, nextState: simBoard.join('')});
        } else {
          const blockIdx = simFindWinMove(simBoard, PLAYER);
          if(blockIdx !== -1){
            simBoard[blockIdx] = AI;
            simMoveHistory.push({state: curState, action: blockIdx, nextState: simBoard.join('')});
          } else {
            if(!qTable[curState]) qTable[curState] = {};
            av.forEach(a=>{ if(qTable[curState][a] === undefined) qTable[curState][a] = 0.0; });
            // epsilon decision for training should follow global EPSILON
            let chosen;
            if(Math.random() < EPSILON) chosen = av[Math.floor(Math.random()*av.length)];
            else {
              let maxQ = -Infinity, best=[];
              av.forEach(a=>{ const q = qTable[curState][a] ?? 0.0; if(q>maxQ){maxQ=q;best=[a];} else if(q===maxQ){best.push(a);} });
              chosen = best.length ? best[Math.floor(Math.random()*best.length)] : av[Math.floor(Math.random()*av.length)];
            }
            simBoard[chosen] = AI;
            simMoveHistory.push({state: curState, action: chosen, nextState: simBoard.join('')});
          }
        }
        const res = simCheckWinner(simBoard);
        if(res.winner){
          simActive=false;
          applySimUpdates(simMoveHistory, res.winner === AI ? +1 : (res.winner === PLAYER ? -1 : 0));
          break;
        }
        simPlayerTurn = true;
      }
    } // end while

    // After simulation finishes, resolve
    resolve();
  });
}

/* applySimUpdates: update global qTable based on simulated AI moveHistory and reward */
function applySimUpdates(simMoveHistory, finalReward){
  // append simulated AI moves to global learning update
  // Use same Q update routine on a copy: we directly update qTable
  let reward = finalReward;
  for(let i=simMoveHistory.length-1;i>=0;i--){
    const {state, action, nextState} = simMoveHistory[i];
    if(!qTable[state]) qTable[state] = {};
    if(qTable[state][action] === undefined) qTable[state][action] = 0.0;
    const currentQ = qTable[state][action];
    let maxNextQ = 0;
    if(qTable[nextState]){ const vals = Object.values(qTable[nextState]); if(vals.length) maxNextQ = Math.max(...vals); }
    const target = reward + (DISCOUNT * maxNextQ);
    const newQ = currentQ + (LEARNING_RATE * (target - currentQ));
    qTable[state][action] = newQ;
    reward = 0;
  }
  // persist periodically (but to keep fast training, we save after training loop)
}

/* ---------- Q persist after training loop ---------- */
/* Note: runTraining will call saveQTable at the end. But to be safe, we also save occasionally. */

/* ---------- Utility: find winner ---------- */
function checkWinner(board){
  const lines = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]];
  for(const [a,b,c] of lines){
    if(board[a] !== '_' && board[a] === board[b] && board[b] === board[c]) return {winner: board[a], indices:[a,b,c]};
  }
  if(board.every(cell => cell !== '_')) return {winner:'draw', indices:[]};
  return {winner:null, indices:[]};
}

/* ---------- Particle effect ---------- */
function resizeCanvas(){ particleCanvas.width = window.innerWidth; particleCanvas.height = window.innerHeight; }
function startParticles(){
  particles=[]; for(let i=0;i<80;i++){ particles.push({ x: window.innerWidth/2 + (Math.random()-0.5)*200, y: window.innerHeight/2 + (Math.random()-0.5)*120, vx:(Math.random()-0.5)*6, vy:-Math.random()*6 - 1, life:Math.random()*80+40, size:Math.random()*4+2, color:`rgba(${Math.floor(70+Math.random()*185)},${Math.floor(120+Math.random()*135)},255,1)` }); }
  requestAnimationFrame(particleLoop);
  setTimeout(()=>{ particles=[]; pcCtx.clearRect(0,0,particleCanvas.width, particleCanvas.height); }, 2400);
}
function particleLoop(){
  pcCtx.clearRect(0,0,particleCanvas.width, particleCanvas.height);
  for(const p of particles){
    p.x += p.vx; p.y += p.vy; p.vy += 0.12; p.life -= 1;
    pcCtx.beginPath(); pcCtx.arc(p.x,p.y,p.size,0,Math.PI*2); pcCtx.fillStyle = p.color; pcCtx.fill();
  }
  particles = particles.filter(p=>p.life>0);
  if(particles.length) requestAnimationFrame(particleLoop);
}

/* ---------- Keyboard shortcut ---------- */
window.addEventListener('keydown', e=>{ if(e.key.toLowerCase()==='r'){ newRound(); hideResult(); } });

/* ---------- Save & Load after training ---------- */
async function runTraining(totalGames){
  trainingRunning = true;
  trainProgress.style.display = 'block';
  trainProgressBar.style.width = '0%';
  const originalEps = EPSILON;
  const decay = decayEpsCheckbox.checked;
  // run in chunks to avoid blocking
  const chunk = 200; // games per micro-task chunk
  for(let i=0;i<totalGames; i+=chunk){
    const upto = Math.min(totalGames, i + chunk);
    for(let g=i; g<upto; g++){
      if(decay) EPSILON = Math.max(0.01, originalEps * (1 - (g/totalGames)));
      // simulate one game fast and update qTable
      await simulateOneGame(); // this returns Promise resolved immediately in current implementation
    }
    // update UI & yield
    trainProgressBar.style.width = Math.round(((upto)/totalGames)*100) + '%';
    qStatesCountEl.textContent = Object.keys(qTable).length;
    await new Promise(r => setTimeout(r, 10)); // brief pause to keep UI responsive
  }
  // end training
  EPSILON = originalEps;
  saveQTable();
  trainingRunning = false;
  trainProgress.style.display = 'none';
  updateUI();
  alert('Training selesai: ' + totalGames + ' games. Q-states: ' + Object.keys(qTable).length);
}

/* ---------- simulateOneGame wrapper used in chunked training ----------
   This version uses synchronous loop but wrapped in Promise to yield control
*/
function simulateOneGame(){
  return new Promise(resolve=>{
    let simBoard = Array(9).fill('_');
    let simPlayerTurn = true;
    let simMoveHistory = [];
    let simActive = true;

    while(simActive){
      if(simPlayerTurn){
        const pWin = findWinningMoveSim(simBoard, PLAYER);
        let chosen;
        if(pWin !== -1) chosen = pWin;
        else {
          const av = availableMoves(simBoard);
          chosen = av[Math.floor(Math.random()*av.length)];
        }
        simBoard[chosen] = PLAYER;
        const res = checkWinner(simBoard);
        if(res.winner){
          // AI reward
          applySimUpdates(simMoveHistory, res.winner === AI ? +1 : (res.winner === PLAYER ? -1 : 0));
          simActive=false; break;
        }
        simPlayerTurn = false;
      } else {
        // AI move logic (same as real AI)
        const curState = simBoard.join('');
        const avail = availableMoves(simBoard);
        if(avail.length === 0){ applySimUpdates(simMoveHistory, 0); simActive=false; break; }
        const winIdx = findWinningMoveSim(simBoard, AI);
        if(winIdx !== -1){
          simBoard[winIdx] = AI;
          simMoveHistory.push({state: curState, action: winIdx, nextState: simBoard.join('')});
        } else {
          const blockIdx = findWinningMoveSim(simBoard, PLAYER);
          if(blockIdx !== -1){
            simBoard[blockIdx] = AI;
            simMoveHistory.push({state: curState, action: blockIdx, nextState: simBoard.join('')});
          } else {
            if(!qTable[curState]) qTable[curState] = {};
            avail.forEach(a=>{ if(qTable[curState][a] === undefined) qTable[curState][a] = 0.0; });
            let chosen;
            if(Math.random() < EPSILON) chosen = avail[Math.floor(Math.random()*avail.length)];
            else {
              let maxQ = -Infinity, best=[];
              avail.forEach(a=>{ const q = qTable[curState][a] ?? 0.0; if(q>maxQ){maxQ=q;best=[a];} else if(q===maxQ){best.push(a);} });
              chosen = best.length ? best[Math.floor(Math.random()*best.length)] : avail[Math.floor(Math.random()*avail.length)];
            }
            simBoard[chosen] = AI;
            simMoveHistory.push({state: curState, action: chosen, nextState: simBoard.join('')});
          }
        }
        const res = checkWinner(simBoard);
        if(res.winner){
          applySimUpdates(simMoveHistory, res.winner === AI ? +1 : (res.winner === PLAYER ? -1 : 0));
          simActive=false; break;
        }
        simPlayerTurn = true;
      }
    } // end while
    resolve();
  });
}

/* helper used in simulateOneGame (local tactical) */
function findWinningMoveSim(board, symbol){
  const av = availableMoves(board);
  for(const idx of av){
    const copy = board.slice(); copy[idx] = symbol;
    const r = checkWinner(copy);
    if(r.winner === symbol) return idx;
  }
  return -1;
}

/* ---------- Utility: expose newRound initially ---------- */
updateUI();

/* ---------- END OF SCRIPT ---------- */
</script>
</body>
</html>
